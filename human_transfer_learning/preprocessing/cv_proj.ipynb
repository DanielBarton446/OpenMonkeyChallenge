{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv_proj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Configuration**"
      ],
      "metadata": {
        "id": "2kXX9FV9NQZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsmJI-k4v3-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e6bf75-ae1e-42d2-9d3b-6fd9d8d31157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7m9eBkd9LSKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install CocoDataset==0.1.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJjFo0VkrR2f",
        "outputId": "ccabe9b4-7459-4ef6-9317-32a77ea23a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting CocoDataset==0.1.2\n",
            "  Downloading CocoDataset-0.1.2-py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from CocoDataset==0.1.2) (2.0.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->CocoDataset==0.1.2) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools->CocoDataset==0.1.2) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (1.15.0)\n",
            "Installing collected packages: CocoDataset\n",
            "Successfully installed CocoDataset-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip /content/annotations_trainval2017.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFWREXdQrVeE",
        "outputId": "221f8932-45e0-487f-cce7-7ec80c01f193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-28 01:48:16--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.205.195\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.205.195|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  46.9MB/s    in 5.6s    \n",
            "\n",
            "2022-04-28 01:48:21 (43.4 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  /content/annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Json file -> Filtered Json File**"
      ],
      "metadata": {
        "id": "HbDQwZFtNYOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "fp = open(\"/content/annotations/person_keypoints_train2017.json\")\n",
        "Keypoints_Json = json.load(fp)"
      ],
      "metadata": {
        "id": "-gUFYoEir_-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_annotations = []\n",
        "selected_images = []\n",
        "selected_img_id =[]\n",
        "length_anno = len(Keypoints_Json[\"annotations\"])\n",
        "length_img = len(Keypoints_Json[\"images\"])\n",
        "print(\"num annotation:\", length_anno)\n",
        "print(\"num images:\", length_img)\n",
        "count = 0\n",
        "for i in range(length_anno):\n",
        "  if (Keypoints_Json[\"annotations\"][i][\"num_keypoints\"] >= 16):\n",
        "    count+=1\n",
        "    selected_annotations.append(Keypoints_Json[\"annotations\"][i])\n",
        "    selected_img_id.append(Keypoints_Json[\"annotations\"][i][\"image_id\"])\n",
        "print(\"num annoations with keypoints greater than 8: \",count)\n",
        "         \n",
        "          \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6dwdmy8sc-L",
        "outputId": "db5c77e5-c5de-4e79-9737-9d01fa5d9fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num annotation: 262465\n",
            "num images: 118287\n",
            "num annoations with keypoints greater than 8:  24123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_img_id = []\n",
        "count = 0\n",
        "for i in range(length_img):\n",
        "  if(Keypoints_Json[\"images\"][i][\"id\"] in selected_img_id):\n",
        "    count += 1\n",
        "    img_img_id.append(Keypoints_Json[\"images\"][i][\"id\"])\n",
        "    selected_images.append(Keypoints_Json[\"images\"][i])\n",
        "print(\"number of image id's that match\", count)"
      ],
      "metadata": {
        "id": "go8ptnaPuZ_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3b1c33-8939-4c42-9678-0db76b41586b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of image id's that match 16986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revised_selected_annotations = []\n",
        "count = 0\n",
        "for i in range(len(selected_annotations)):\n",
        "  if(selected_annotations[i][\"image_id\"] in img_img_id):\n",
        "    revised_selected_annotations.append(selected_annotations[i])\n",
        "    count += 1\n",
        "print(count)\n",
        "\n",
        "print(len(revised_selected_annotations))\n",
        "print(len(selected_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FBy2Hgmazx",
        "outputId": "94edd76e-7aec-47ac-9beb-308d8e98ee4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116021\n",
            "116021\n",
            "49431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Keypoints_Json_selected= Keypoints_Json\n",
        "Keypoints_Json_selected[\"annotations\"] = revised_selected_annotations\n",
        "Keypoints_Json_selected[\"images\"]= selected_images"
      ],
      "metadata": {
        "id": "7pbHp73D2CCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/HTL/person_annotations.json\", \"w\") as outfile:\n",
        "    json.dump(Keypoints_Json_selected, outfile)\n",
        "with open(\"/content/drive/Shareddrives/CSCI5561/Project/TransferLearning/person_annotations.json\", \"w\") as outfile:\n",
        "    json.dump(Keypoints_Json_selected, outfile)"
      ],
      "metadata": {
        "id": "bXkAGs0M3oAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "fp2 = open(\"/content/drive/MyDrive/HTL/person_annotations.json\")\n",
        "img_anotation_json = json.load(fp2)\n",
        "print(len(img_anotation_json[\"annotations\"]))\n",
        "for i in range(len(img_anotation_json[\"annotations\"])):\n",
        "  temp = []\n",
        "  for j in range(0,len(img_anotation_json[\"annotations\"][i][\"keypoints\"]) - 1):\n",
        "    if ((j+1) % 3 == 0 and j > 0):\n",
        "      continue\n",
        "    else:\n",
        "      temp.append(img_anotation_json[\"annotations\"][i][\"keypoints\"][j])\n",
        "  img_anotation_json[\"annotations\"][i][\"keypoints\"] = temp\n",
        "print(img_anotation_json[\"annotations\"][0][\"keypoints\"])\n",
        "with open(\"/content/drive/MyDrive/HTL/person_annotations_no_vis.json\", \"w\") as outfile:\n",
        "    json.dump(img_anotation_json, outfile)"
      ],
      "metadata": {
        "id": "Aq1nrJlGfocD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532ef946-6a29-4030-86c8-7be8877a5970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116021\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 325, 160, 398, 177, 0, 0, 437, 238, 0, 0, 477, 270, 287, 255, 339, 267, 0, 0, 423, 314, 0, 0, 355, 367]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\"human keypoints\": [ 0-1\"nose\", 2-3\"left_eye\", 4-5\"right_eye\", 6-7\"left_ear\", 8-9\"right_ear\", 10-11\"left_shoulder\", 12-13\"right_shoulder\", 14-15\"left_elbow\", 16-17\"right_elbow\", 18-19\"left_wrist\", 20-21\"right_wrist\", 22-23\"left_hip\", 24-25\"right_hip\", 26-27\"left_knee\", 28-29\"right_knee\", 30-31\"left_ankle\", 32-33\"right_ankle\" ]"
      ],
      "metadata": {
        "id": "sNVJ0lv-btQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "monkey keypoints 0-1:Right eye, 2-3:left eye, 4-5:Nose, 6-7:Head, 8-9:Neck, 10-11:Right shoulder, 12-13: Right elbow, 14-15:right wrist, 16-17:Left shoulder, 18-19:Left elbow, 20-21:Left wrist, 22-23:Hip, 24-25: Right knee, 26-27: Right ankle, 28-29: Left knee, 30-31:left ankle, 32-33:tail"
      ],
      "metadata": {
        "id": "CnnuOQQ2bxCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "fp = open(\"/content/drive/Shareddrives/CSCI5561/Project/OpenMonkeyChallenge/Annotations/train_annotation.json\")\n",
        "fp2 = open(\"/content/drive/MyDrive/HTL/person_annotations_no_vis.json\")\n",
        "\n",
        "monkey_Keypoints_Json = json.load(fp)\n",
        "human_Keypoints_Json = json.load(fp2)\n",
        "\n",
        "print(\"Length of monkey json: \",len(monkey_Keypoints_Json[\"data\"]))\n",
        "print(\"Length of human json: \",len(human_Keypoints_Json[\"images\"]))\n",
        "\n",
        "for i in range(len(human_Keypoints_Json[\"images\"])):\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"file\"] = human_Keypoints_Json[\"images\"][i][\"file_name\"]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"species\"] = \"Human\"\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"bbox\"] = int(human_Keypoints_Json[\"annotations\"][i][\"bbox\"])\n",
        "  #map landmarks and visibility properly\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][0] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][4]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][1] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][5]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][2] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][2]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][3] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][3]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][4] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][0]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][5] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][1]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][6] = 0\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][7] = 0\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][8] = 0\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][9] = 0\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][10] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][12]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][11] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][13]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][12] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][16]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][13] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][17]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][14] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][20]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][15] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][21]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][16] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][10]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][17] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][11]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][18] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][14]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][19] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][15]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][20] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][18]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][21] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][19]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][22] = int((human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][22] + human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][24]) /2)\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][23] = int((human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][23] + human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][25]) /2)\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][24] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][28]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][25] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][29]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][26] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][32]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][27] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][33]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][28] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][26]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][29] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][27]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][30] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][30]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][31] = human_Keypoints_Json[\"annotations\"][i][\"keypoints\"][31]\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][32] = 0\n",
        "  monkey_Keypoints_Json[\"data\"][i][\"landmarks\"][33] = 0\n",
        "\n",
        "\n",
        "del monkey_Keypoints_Json[\"data\"][49431:66917]\n",
        "print(\"Length of monkey json: \",len(monkey_Keypoints_Json[\"data\"]))\n",
        "print(\"Length of human json: \",len(human_Keypoints_Json[\"images\"]))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/HTL/person_annotations_OMC_format.json\", \"w\") as outfile:\n",
        "    json.dump(monkey_Keypoints_Json, outfile)\n",
        "with open(\"/content/drive/Shareddrives/CSCI5561/Project/TransferLearning/person_annotations_OMC_format.json\", \"w\") as outfile:\n",
        "    json.dump(monkey_Keypoints_Json, outfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X4TDv4LRI-g",
        "outputId": "accc36f4-3fab-4a51-a3bd-d6cf806d8d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of monkey json:  66917\n",
            "Length of human json:  49431\n",
            "Length of monkey json:  49431\n",
            "Length of human json:  49431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Json File output to the .json**"
      ],
      "metadata": {
        "id": "p9BpYRD1Njzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import requests\n",
        "import os\n",
        "\n",
        "coco = COCO(\"/content/drive/MyDrive/HTL/person_annotations.json\")\n",
        "# Specify a list of category names of interest\n",
        "catIds = coco.getCatIds(catNms=[\"person\"])\n",
        "# Get the corresponding image ids and images using loadImgs\n",
        "imgIds = coco.getImgIds(catIds=catIds)\n",
        "images = coco.loadImgs(imgIds)\n",
        "# Save the images into a local folder\n",
        "count=0\n",
        "# specified count images for class name\n",
        "for im in images:\n",
        "    img_data = requests.get(im['coco_url']).content\n",
        "    with open(\"/content/drive/Shareddrives/CSCI5561/Project/TransferLearning/images\" +'/'+ im['file_name'], 'wb') as handler:\n",
        "        handler.write(img_data)\n",
        "    count+=1\n",
        "    if count>200:\n",
        "        print('finished images download')\n",
        "        break\n",
        "    print('no.of image:',count)"
      ],
      "metadata": {
        "id": "J_augvwnFs_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_dataset import coco_dataset_download as cocod\n",
        "\n",
        "class_name='person'  #class name example \n",
        "images_count= 50000     #count of images  \n",
        "annotations_path='/content/drive/MyDrive/HTL/person_annotations.json' #path of coco dataset annotations \n",
        "#call download function \n",
        "cocod.coco_dataset_download(class_name,images_count,annotations_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "wWPQs4PW8vXW",
        "outputId": "0abe6ad7-51ab-4ebe-9e10-b31d9948aabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=8.60s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-3a6aecc297e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mannotations_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/HTL/person_annotations.json'\u001b[0m \u001b[0;31m#path of coco dataset annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#call download function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcocod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_dataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannotations_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/coco_dataset/coco_dataset_download.py\u001b[0m in \u001b[0;36mcoco_dataset_download\u001b[0;34m(class_name, images_count, annotations_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimgIds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Save the images into a local folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'person'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over json object\n",
        "# for every single file name, to see if it exists in the file we downloaded earlier\n",
        "from os.path import exists\n",
        "fp2 = open(\"/content/drive/MyDrive/cv_proj/person_keypoints_selectedTrain.json\")\n",
        "revision_keypoints_json = json.load(fp2)\n",
        "tes_count = 0\n",
        "for i in range (len(revision_keypoints_json[\"images\"])):\n",
        "  path_to_file =\"/content/drive/MyDrive/cv_proj/person/\"+ revision_keypoints_json[\"images\"][i][\"file_name\"]\n",
        "  if(exists(path_to_file)):\n",
        "    tes_count +=1\n",
        "print(tes_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH2TFJE79w8k",
        "outputId": "f36d4325-004c-490c-fb36-bc7e4e27121e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Revision of Keypoints**"
      ],
      "metadata": {
        "id": "2VqxPySjM1sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(revision_keypoints_json[\"annotations\"][0][\"keypoints\"])\n",
        "print(revision_keypoints_json[\"annotations\"][0][\"image_id\"])\n",
        "for i in range(len(revision_keypoints_json[\"images\"])):\n",
        "  if revision_keypoints_json[\"images\"][i][\"id\"]==44474 :\n",
        "    print(revision_keypoints_json[\"images\"][i][\"file_name\"])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCrjEIy8Iwmc",
        "outputId": "403334bf-46a3-4c9e-8d51-40f70c5cd8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[145, 113, 2, 158, 96, 2, 124, 97, 2, 184, 85, 2, 84, 89, 2, 184, 141, 2, 77, 153, 2, 219, 205, 2, 67, 229, 2, 183, 193, 2, 125, 182, 2, 174, 279, 2, 97, 287, 2, 223, 230, 2, 50, 302, 2, 287, 312, 2, 70, 372, 2]\n",
            "44474\n",
            "COCO_train2014_000000044474.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting the ears and Merge the hips"
      ],
      "metadata": {
        "id": "ZqzQ5Sae9TGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fp2 = open(\"/content/drive/MyDrive/cv_proj/person_keypoints_selectedTrain.json\")\n",
        "img_anotation_json = json.load(fp2)\n",
        "print(\"before deleteting ears and merge hip \",len(img_anotation_json[\"annotations\"][0][\"keypoints\"]))\n",
        "for i in range(len(img_anotation_json[\"annotations\"])):\n",
        "  anno_index = img_anotation_json[\"annotations\"][i][\"keypoints\"]\n",
        "  # 12 and 13 keypoints on hip 33 34 35 36 37 38 \n",
        "  anno_index[33]= int((anno_index[33] +anno_index[36])/2)\n",
        "  anno_index[34]= int((anno_index[34] +anno_index[37])/2)\n",
        "  anno_index[35]= int((anno_index[35] +anno_index[38])/2)\n",
        "  for j in range(12):\n",
        "    anno_index[j+36]=anno_index[j+39]\n",
        "  del anno_index[48:52]\n",
        "  #delete the ears\n",
        "  del anno_index[10:16]\n",
        "  img_anotation_json[\"annotations\"][i][\"keypoints\"] = anno_index\n",
        "print(\"after deleteting ears and merge hip\",len(anno_index))\n",
        "with open(\"/content/drive/MyDrive/cv_proj/img_anot.json\", \"w\") as outfile:\n",
        "    json.dump(img_anotation_json, outfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rY8UwLP3lth",
        "outputId": "8500cc88-3859-41fe-f3ca-41602132e1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before deleteting ears and merge hip  51\n",
            "after deleteting ears and merge hip 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "# Keypoint visualization(teal color centered at keypoint)\n",
        "\n",
        "fp3 = open(\"/content/drive/MyDrive/HTL/person_annotations.json\")\n",
        "img_anotation_json = json.load(fp3)\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/HTL/image_visualization\"\n",
        "if os.path.isdir(output_dir):\n",
        "  shutil.rmtree(output_dir) \n",
        "\n",
        "for i in range(5):\n",
        "  idx = random.randint(0, 4846)\n",
        "  img_path =\"/content/drive/Shareddrives/CSCI5561/Project/TransferLearning/images\"+ img_anotation_json[\"images\"][idx][\"file_name\"]\n",
        "  img = cv2.imread(img_path)\n",
        "\n",
        "  for j in range ((len(img_anotation_json[\"annotations\"]))):\n",
        "    if img_anotation_json[\"annotations\"][j][\"image_id\"]== img_anotation_json[\"images\"][idx][\"id\"]:\n",
        "      keypoints_anno = j\n",
        "      break\n",
        "  keypoints = img_anotation_json[\"annotations\"][keypoints_anno][\"keypoints\"]\n",
        "      \n",
        "  k = 0\n",
        "  while(k<len(keypoints)):\n",
        "      x = keypoints[k]\n",
        "      y = keypoints[k+1]\n",
        "      k+=3\n",
        "      for v in range(3):\n",
        "        for u in range(3):\n",
        "          img[y+v][x+u] = [255, 0, 0]\n",
        "\n",
        "  if not os.path.exists(output_dir):\n",
        "    print(\"MADE DIRECTORY: \" + output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "  cv2.imwrite(output_dir + img_anotation_json[\"images\"][idx][\"file_name\"], img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Kd5zcCt24VaD",
        "outputId": "44c47393-8a09-4218-bfca-38e1e80a6a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-80ecc57c5cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}